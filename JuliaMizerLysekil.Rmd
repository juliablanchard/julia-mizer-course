---
title: "Confronting Size Spectrum Theory with Data"
author: Julia L. Blanchard
date: 05/07/2019
place: Lysekil Training Course, Sweden, Sept. 6-9, 2019
output:
  pdf_document: default
  html_document: default
---


# Introduction

Empiricists have been reporting changes in the size spectrum for many years, such as Sheldon and colleague's early observations (Sheldon et al). Even prior to that Ghilarov reported that log biomass would be equivalent in log size classess - we he showed for soil organisms - at large scales (Polishchuk ref). Fisheries scientists have been analysing trends in the fish community size spectrum for many years as well and have examined its' potential use as an indicator for the ecosystem effects of fishing (Jennings et al., Shin et al. 2005, Daan et al. 2005, Blanchard et al. 2005 etc.). This is because the slope of the "fished"" component of the size spectrum been observed to become steeper through time - an effect the loss of larger individuals through fishing mortality. The intercept of teh size spectrum on a log-log scale is alos important and is thought to be influenced by the amount and production of smaller primary producers in the ecosystem (Bianchi et al. 2001).

In this section of the course we will explore how we can learn about models by fitting size spectrum ecological models to data using the "mizer" R package. Later on, we will use "calibrated" model(s) to explore the dynamics of the system through time and carry out fishing (and climate change) scenarios. 

Recall, there are three different kinds of size spectrum models in mizer, of increasing complexity: 
1) community model: purely size-based and representative of a single but  "average" species across the whole community 
2) trait-based model, which disaggregates the size spectrum into differentgroups with different life-histories, through differences in each "species" asymptotic which determines
other life-history parameters such as the size at maturity (Hartvig et al. 2011, Andersen & Pedersen, 2010)
3) multispecies model - which has the same equations and parameters as the trait-based model but is parameterised to represent multiple species in a real system, where each species can have many differing species-specific traits (Blanchard et al. 2014). 
4) scale-free model (Gustav can explain that one!)

Here, we will focus mostly on  multispecies models but the same approach can be carried out with the other models. Actually since these are general approaches, they can be used with *any* deterministic mechanistic models. To start with though we will consider confronting the simplest model - the community model - with data on the community size spectrum (What is a size spectrum? See Ken's section!).

## Example #1 - Fitting the community model to size spectrum data

```{r}
#get required packages
require(mizer)
require(tidyverse)

#lets's read in some north sea community size spectrum data
css<-read.table("data/sizespecobs.txt",header=T)

#select data for year 2000
css <- css %>%
  filter(year == "2000", Nden > 0) %>%
  select(midw, Nden)

#have a look at plot
plot(log(css$midw),log(css$Nden),xlab="midpoint of weight class (g)", ylab="number density")

# we can fit a smoother to these points to generate easy access "observations" to compare with model later
lo<-loess(log(css$Nden)~log(css$midw),span=0.2)
points(log(css$midw),predict(lo),typ="l")
```

The first question we will pose here is: How do we fit a simple community size spectrum model to community size spectrum data? To answer this we ask: What do the community size spectrum model parameters need to be to best capture observations of the community size spectrum? We will consider only two parameters - the level of fishing effort (here, simply a multiplier of fishing mortality rate) and the background resource carrying capacity which are known to affect the size spectrum.

First let's set up the communiy size spectrum model and plot it.

```{r}
params <- set_community_model(knife_edge_size = 10)
sim <- project(params, effort = 0, t_max = 100, dt=0.1, dx=200)
plotSpectra(sim)
```

We could stop here and simply compare the modelled size spectrum slopes and intercepts to the observed ones shown above. But instead  we are going to go a bit further  - but starting simple -  and simply run a range of parameter values, for *effort* and *kappa*. 


So, we want the model to be able to run over a range of parameters that we pass to it. 

```{r}
# set up function to run model and output the predicted size spectrum
runmodel<-function(parms){# set up and run!
params <- set_community_model(knife_edge_size = 10,kappa=parms$kappa)
sim <- project(params, effort = parms$effort, t_max = 200, dt=0.1)

# select last 10 years of output (should be time-averaged)
# slope only
# output<-mean(getCommunitySlope(sim,min_w=16,max_w=1600)[190:200,1])
# or whole size spectrum
output <-apply(sim@n,c(2,3),mean)
return(output)
}
```

We will interrogate the outputs that best "fit" the data. First we need to specify what we mean by our "best fit".
We will use simple least squares regression and assess the sum of squared errors (SSE) between the observed and the modelled size spectra. We will select and examine the parameter set with the lowest SSE.

```{r}
# set up some initial parameters
parms=data.frame(kappa=0.1,effort=1)
# get data for same weight values
logw <- log(params@w[which(params@w  >= 16 & params@w <= 22000)])
dat <- predict(lo,logw)

# set up error function to compare predictions with observations
sse <- function(parms,dat) {
pred <- log(runmodel(parms)[which(params@w  >= 16 & params@w <= max(css$midw))])
# sum of squared errors
discrep <- pred - dat
return(sum(discrep^2))
}
err<-sse(parms,dat)
#test
err
```

We could skip ahead to  optimisation here to simply find the best parameter set. Instead, to illustrate how this works and to examine the likelihood surface, we will set up a simple grid of parameters. Because the models runs are not actually dependent on each other (they are sequential), we can also do this more quickly with parallel computing.

```{r}
f <- function (par) {
parms$kappa <- par[1]
parms$effort <- par[2]  
sse(parms,dat)
}
# single parameter
kappa <- seq(from=0.05,to=0.1,by=0.05)
effort <- seq(from=0,to=2,by=0.1)
grid <- expand.grid(kappa=kappa,effort=effort)
grid$SSE <- apply(grid,1,f)
```

Let's have a look at the error surface and extract the parameter set that gives the minimum error.

```{r}
# which level of effort has overall least error?
effort.hat <- grid$effort[which.min(grid$SSE)]
kappa.hat <- grid$kappa[which.min(grid$SSE)]
# Basic scatterplot
ggplot(grid, aes(x=effort, y=SSE,col=kappa) ) +
  geom_point() 

```

What do these results suggest about the influence of kappa on the effects of fishing? Next plug the effort.hat and kappa.hat values back into the model and plot the modelled and observed size spectra. How do these look compare to the orginanl data?

```{r}
params <- set_community_model(knife_edge_size = 10,kappa=kappa.hat)
sim <- project(params, effort = effort.hat, t_max = 100, dt=0.1)
w <-dimnames(sim@n)$w
n <-sim@n[100,,]
plot(w,n,log="xy",typ="l",xlim=c(0.1,30000))
#add the data to the plot
points(css$midw,css$Nden, col= "steel blue")

```

## Questions:

The model predictions do pass through the points but the shape of the size spectra look a bit different. Would we get similar results if we just used the modelled and observed size size spectrum slopes and intercepts? What happens if we vary different parameters and different values? 


# Alternate Example # 1 or Example 2: Fantasy multispecies model and data

Let's set up a multispecies model in mizer. This is a fantasy ecosystem so anything goes! These parameters should be familiar from the earlier theory presentations of the trait-based model and we will explain them in more detail in the "Parameterisation" section. Feel free to change them!

## Species-specific parameters
```{r}
require(mizer)
fic.params<-data.frame(matrix(0,5,0))
fic.params$species<-c("Blinky","Dory", "Fluffy","Mermaids","Nessie")
fic.params$w_inf<-c(400,100,3000,40000,100000)
fic.params$w_mat<-c(100,20,500,10000,20000)
fic.params$z0<-c(0.2,0.2,0.14,0.12,0.25) ## mu_0
fic.params$r_max<-c(1e8,1e9,5e6,1e3,1e4)
fic.params$beta<-c(3210,42100,3200,200,30)
fic.params$sigma<-c(1.2,1.4,1.8,2,3)
fic.params$ks<-c(1,1,0.9,0.91,0.54)
fic.params$h<-c(10,14,30,20,32)
fic.params$gamma<-c(1e-9,2e-11,1e-11,6e-10,7e-12)

# interaction matrix
fic.inter<-matrix(1,5,5)
colnames(fic.inter)<-rownames(fic.inter)<-fic.params$species
fic.inter[1,1]<-1;fic.inter[1,2]<-0.8;fic.inter[1,3]<-0.4;fic.inter[1,4]<-0.9;fic.inter[1,5]<-0.8
fic.inter[2,1]<-0.53;fic.inter[2,2]<-0.35;fic.inter[2,3]<-0.6;fic.inter[2,4]<-0.8;fic.inter[2,5]<-0.42
fic.inter[3,1]<-1;fic.inter[3,2]<-0.76;fic.inter[3,3]<-0.5;fic.inter[3,4]<-1;fic.inter[3,5]<-0.72
fic.inter[4,1]<-0.05;fic.inter[4,2]<-0.8;fic.inter[4,3]<-0;fic.inter[4,4]<-0;fic.inter[4,5]<-0.8
fic.inter[5,1]<-1;fic.inter[5,2]<-0.74;fic.inter[5,3]<-1;fic.inter[5,4]<-1;fic.inter[5,5]<-0.9;

# set up and run!
params.fic <- MizerParams(fic.params, fic.inter,r_pp=0.1,lambda=2.2)
sim.fic <- project(params.fic, t_max = 200,dt=0.1)
# show the plot
plot(sim.fic)

```

The plot shows there are some pretty cool size distributions, and other than the largest sea monster (Nessie) struggling to eat enough food, the biomass of each species in the model is approaching a steady state.

Just for fun, let's have a look at who is eating whom!

```{r}
#ADD NEW DIET PLOT HERE :)
```

Now, let's make up some data by adding a bit of normally distrubuted error around the model predictions from the last time step. We can then calculate the error between the "observed" and predicted.

```{r}
pred <- getBiomass(sim.fic)[200,]
names(pred) <- names(getBiomass(sim.fic)[200,])
dat <- as.matrix(read.table("data/ficdata.txt"))
plot(dat,pred,xlab="observed",ylab="predicted",log="xy")
text(dat,pred,names(pred),cex=0.6,col="tomato")
abline(0,1)

```

To start, we will keep things very simple and just vary one or two parameters. We will focus on a highly uncertain specie-specific parameter: Rmax (essentially the carrying capacity of recruits). This parameter is handy as it scales the biomass and abundances for each species. Here we have a simple goal that we'd like to be in the right ball park of the time-averaged biomass values for each species. 

First, we can wrap MizerParams() and project() functions into a function called runmodel() so that we can easily call this later. 

```{r}
runmodel<-function(params, inter){# set up and run!
params.fic <- MizerParams(params, inter)
sim.fic <- project(params.fic, t_max = 200,dt=0.1)
# use the same time slot (should be time-averaged)
output<-getBiomass(sim.fic)[200,]
return(output)
}

```

Next, we  want to calculate the discrepancy between model and data. Again, we will use simple *least squares* to calculate the sum of squared errors between model and data. First, we will build a function to calculate the discrepancy between the model and data.

```{r}
sse <- function(params,inter, dat) {
pred <- runmodel(params, inter)
discrep <- pred - dat
return(sum(discrep^2))
# sum of squared errors
}
err<-sse(fic.params,fic.inter,dat)
err
```

The biomasses of Mermaids and Nessie are not very realistic in terms of distance from the observations. Let's work out whether we can find a better estimates of Rmax for these two species, simply by varying the values of Rmax, relative to the range of default values. 

[Side note: where do these default Rmax values come from? Ken will tell you!]

Setting up a grid of parameter values becomes onerous when we have several parameters all with different ranges and random sampling schemes are known to produce bias.  Many statisticians have devoted their time to developing to optimization algorithms, and there are many of these. Many are implemented in R. For this example we will use nloptr (optim is another popular package you may be familiar with). 

```{r}
f <- function (new_rmax) {
fic.params[fic.params$species==c("Mermaids"),"r_max"] <- new_rmax[1]
fic.params[fic.params$species==c("Nessie"),"r_max"] <- new_rmax[2]
print(sse(fic.params,fic.inter,dat))
print(fic.params[3,"r_max"])
}
# optimisation example
require(nloptr)
new_rmax <- c(1e4,1e3) 
SSE <- optim(new_rmax,f)

#SSE <- nloptr(new_rmax,f,opts=list("algorithm" = "NLOPT_LN_COBYLA"))
```

That seemed to converge very quickly. Let's take a look at what the model looks like now.

```{r}
# put new Rmax values into to model
fic.params[fic.params$species==c("Mermaids"),"r_max"] <- SSE[1]
fic.params[fic.params$species==c("Nessie"),"r_max"] <- SSE[2]
params.fic <- MizerParams(fic.params, fic.inter,r_pp=0.1,lambda=2.2)
sim.fic2 <- project(params.fic, t_max = 200,dt=0.1)

# show the diagnostic plot
plot(sim.fic2)

#check out fit
pred<-getBiomass(sim.fic2)[200,]
plot(dat,pred,xlab="observed",ylab="predicted",log="xy")
abline(0,1)

#look at change in biomasses before and after new parameter estimation.
change<-data.frame(species=names(getBiomass(sim.fic2)[200,]),change=getBiomass(sim.fic2)[200,]/getBiomass(sim.fic)[200,])

# barplot of model biomass change before and after parameter estimation
 ggplot(data=change, aes(x=species, y=change)) +
  geom_bar(stat="identity", width=0.5) +
  theme_bw()
 
 # percentage difference from data
pdiff<-data.frame(species=names(getBiomass(sim.fic2)[200,]),x=((pred-dat)/dat)*100)

# barplot of percentage difference of new modelled biomasses relative to data 
 ggplot(data=pdiff, aes(x=species, y=x)) +
  geom_bar(stat="identity", width=0.5) +
  theme_bw()
 


```


It seems like our best estimate results in a model with a lot more Nessie!
Also the actual fits are not that great in percentage terms. The other species seem okay, but there is 100% more Nessie biomass in the model than the observations. Take a few minutes to discuss *Why?* 

Too easy? Yes! Typically optimisation takes a lot longer than this. Here we cheated a bit and our initial model parameters values were not that unreasonable compared to the observations (they were actually generated by adding some noise around the observations!). Change the initial Rmax values and see what happens.

Also, we need to think about what we consider to be a good enough fit to data? This largely depends on the questions we  are aksing with the model. One important aspect is identifying what our expectations are in terms of the emergent ecological properties of the model. To do this we can examine e.g. growth curves, species' and community size spectra,mortality rates, responses to fishing.


[Gustav's RShiny app is a useful way to examine and verify these model predictions before and after model is calibrated]


#### Example # 2 or 3  - Time-averaged Optimisation OR Time-series Optimisation

That was just for our given set of fantasy model parameters and some made up data - a fantasy indeed. Real ecology is so much messier! Also we would like to do better than just evaluating what the smallest error is for  two species' Rmax, across a range of values.  We would like to learn about what values the model parameters would need to be to best capture the data. We can optimise all of the species' Rmax parameters simultaneously to see how well we can fit the data.  

This time we will use the North Sea model - but instead of using the provided calibrated North Sea Rmax values in mizer from Blanchard et al. 2014 (who tried their best at the time...) we will reset the Rmax values and redo the analysis using a few new packages in R. We previously used optim (combined with brute force in the form of penaly functions!) for the Blanchard et al. 2014 paper. Since then, we have moved on a bit and so has the fast paced world of computation and R. We have also develop Bayesian methods with mizer (Spence et al. 2016) but these are very skillful and time consuming approaches, perhaps more than is warranted investing for some applications. One issue with optimisation with these modes though is that the likelihood surface tends to contain lots of local minima. Also for lots of the parameter values the model outputs are not plausible. 

So, we will start by reducing the parameter space by specifying some ecologically meaningful constraints - by describing some criteria for "what is plausible?"

First, let's check out the model using using the default Rmax values.

```{r}
data(NS_species_params)
data(inter)
params <- MizerParams(NS_species_params, inter)
#run model
sim <- project(params, t_max = 200, effort = 1,dx=200,dt=0.1)
plot(sim)
```




## Reducing the parameter space 

An alternative to running the optimiser and model with initial values is to reduce the parameters space to those values that actually lead the model to plausible, and ecolgically accpetable model outputs. This may be achieved form careful hand-tuning and "pattern-oriented" visual examination  (ref, see Gustav's RShiny example) to achive initial values that are very close to those "optimal values". However, it may also be the case that we would like to learn what range of values can lead to plausible.

## History matching

We sample the parameter space randomly (another approach is the Latin Hypercube Sampling), folllowed by a combination of least squares and history matching (Clark et al. 2003) to evaluate the parameter sets.

We then evaluate the plausibility of these paramters by running the model and evaluationg some criteria. These can be designed to be specific to your study system and reserach questions. For this example, we simply aim for the species in the system to be:
i) within the range of observed catches (+/- 20% of mean catches)

We could also add additonal constraints e.g.
ii) estimated growth parameters are close to ( witin ) empirical estimates 
and 
iii) for species to still coexist when fishing is set to 0 for all species

All parameter sets that do not meet these criteria are implausible and are hence REJECTED. This provides us with a new subset of the parameter space within which we can proceed to sample again via optimisation (with bootstrapping if we wish to examine uncertainies around these values) and/or more sophisticated Bayesian or Approximate Bayesian Computation (Toni et al 2009) techniques to formally examine parameter uncertainity including time-series fitting (Spence et al. 2016, Spence et al. in review).

[Note: we also can use Gustav's RShiny app to examine these outputs].

#### Random sampling


```{r}
#load packages needed
require(lhs)
require(parallel)
# number of samples to be drawn
n<-8*1000
#number of parameter columns
p<- 14
paramset<-randomLHS(n,p)
#write over with random values
paramset[,1:12]<-qunif(paramset[,1:12],1e2,1e12)
```

We will move away from the default values and attempt to gain inference about the Rmax values from the catch data. We will need to rewrite our functions to ensure we pass the optimizer the correct data and parameters. 
```{r}
runmodel<-function(params, inter){ 
# set up and run!
paramsr <- MizerParams(params, inter)
paramsr@species_params$erepro <- 0.01
sim <- project(paramsr, t_max = 200,dt=0.1, effort = 1)
# use the same time slot (should be time-avaeraged)
output<-colMeans(getYield(sim)[150:200,])/1e6
return(output)
}

# function to reject - catch data only
reject <- function(params,dat,inter) {
pred <- runmodel(NS_species_params, inter)
reject <-sum(ifelse(pred > dat+(0.20*dat) | pred < dat-(0.20*dat),1,0)) > 0
# let's also calculate sum of squared errors
discrep <- pred - dat
err <- sum(discrep^2)
return(list(reject=reject,error=err,params=params$r_max))
}

```

# Run the rejection algorithm for all of the saved output files and add column of "reject" variable to input table

[this may be a good enough departure point for your ballpark results]

### Optimisation in the reduced parameter space
To use optim ( or noptlr or another package)  we need to specify the function we want to minimize and the initial values for the parameters. Starting from this point, the package's algorithms will search the parameter space for the value that minimizes the value of our objective function (sse).

First, we will write an objective function to try to estimate the Rmax values for all 12 species simultaneously. We'll work on the log-transformed values for Rmax parameters as well as the observed catches. Note that Blanchard et al. 2014 used catches and SSB from stock assessment models to estimate Rmax and kappa. Here, to avoid the model bias we will use catches only (and as in Spence et al.2016). 

```{r,warning=T}
#get data on catches over time-averaged period
catch <- read.delim("data/catches.txt")
dat <- catch[,"Catch_8595"]

f <- function (par) {
NS_species_params$r_max <- as.numeric(par[1:12])
reject(params=NS_species_params,dat,inter)
}

#system.time({
#out <- apply(paramset,1,FUN=f)
#})

#  user  system elapsed 
# 77.188   8.755  85.749

# speed up by running on cluster
numCores <-detectCores()

cl <- makeForkCluster(getOption("cl.cores", numCores))
clusterExport(cl, as.list(ls()))

system.time({
results <- parRapply(cl=cl,paramset,f)
})

#  user  system elapsed 
#  0.095   0.065  29.624

# When you're done, clean up the cluster
stopCluster(cl)
```

We then pass the parameters to the functions and run the optimiser - and hope for the best! Let's take a break here...

```{r}
f <- function (par) {
NS_species_params$r_max <- exp(par)
sse(params,dat,inter)
}

```

Now let's see how these optimised values  of Rmax the time-averaged model fits. 
```{r}
params@species_params$r_max <- fit$solution
#re-run model to check
sim <- project(params, t_max = 200, effort = 1,dx=200,dt=0.1)
plot(sim)
# check pred-obs plot
pred<-colMeans(getYield(sim)[100:200,])/1e6
plot(dat,pred)
abline(0,1)
```


# Part 2: Dynamics: Modelling Changes in Fish Communities Through Time

# TO ADD Example 3 - How does the community change through time in response to changes in fishing. 

How can we model changes through time from fishing?  Unless already shown in time series calibration above (in which case can be an examination of scenario projection after time series).

# TO ADD Example 4 - How can we model changes through time from climate change? 

Show example run and how to set up model and force with temperature and/or background resource changes through time (we can use extended mizer version "thermizer" for this example as it's published, but we have other dev branches in prep). Leads into topics discussed in worksahop...

# TO ADD Questions for Small Group Discussion:  
 We can ask the class to break up into groups to decide on a question each to address together and report back on.

# Some suggestions:
-Does the climate change enabled model fit the data any better through time?
-Do all species responf in the same way to the combined effects of fishing and climate change forcings?
-How quickly do different fish recover from fishing?
-What happens when we add species that are not fish species?




